model:
  clip_model: "ViT-B/32"  # Start with smallest CLIP
  bridge_dim: 512
  bridge_layers: 2
  bridge_heads: 8
  dropout: 0.1
  use_hyperbolic: true
  temperature: 0.07

training:
  batch_size: 16  # Will use gradient accumulation
  grad_accum_steps: 4  # Effective batch = 64
  learning_rate: 1e-4
  weight_decay: 0.01
  epochs: 30
  warmup_steps: 500
  
  # Memory optimization
  mixed_precision: true
  gradient_checkpointing: false  # Only if needed
  
data:
  train_dataset: "imagenet_subset"  # Start with subset
  val_dataset: "imagenet_val"
  num_workers: 4
  pin_memory: true
  
uncertainty:
  geometric_weight: 1.0
  angular_weight: 0.5
  calibration_bins: 15

test_time:
  adaptation_steps: 1  # Single-pass
  adaptation_lr: 0.001
  cache_size: 32  # For K-NN style adaptation